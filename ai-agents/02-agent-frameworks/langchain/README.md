# LangChain: Foundation Agent Framework ğŸ”—

> Master the fundamentals of LLM agents with LangChain

---

## ğŸ¯ What You'll Learn

LangChain is the **foundational framework** for building LLM applications. It provides:

- ğŸ”— **Chains** - Connect LLM calls together
- ğŸ“ **Prompts** - Dynamic prompt templates
- ğŸ§  **Memory** - Conversation history management
- ğŸ› ï¸ **Tools** - Give agents capabilities
- ğŸ”„ **Sequences** - Multi-step workflows

**Time Required:** 4-5 hours

---

## ğŸ“‚ Files in This Section

```
langchain/
â”œâ”€â”€ README.md                    â† You are here
â”œâ”€â”€ 00_installation.py          â† Verify setup
â”œâ”€â”€ 01_basic_chain.py           â† Your first chain
â”œâ”€â”€ 02_prompt_templates.py      â† Dynamic prompts
â”œâ”€â”€ 03_chains_with_memory.py    â† Conversation memory
â”œâ”€â”€ 04_tools_integration.py     â† Tool-calling agents
â”œâ”€â”€ 05_sequential_chains.py     â† Multi-step workflows
â”œâ”€â”€ 06_router_chains.py         â† Conditional routing
â””â”€â”€ 07_production_agent.py      â† Complete agent system
```

---

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install langchain langchain-ollama langchain-core requests

# Verify Ollama
ollama list  # Should show qwen3:8b

# Run first example
python 01_basic_chain.py
```

---

## ğŸ“– Progressive Learning Path

### 00 - Installation & Setup
**Concept:** Verify everything works
**You'll learn:** Testing Ollama + LangChain integration

### 01 - Basic Chain
**Concept:** Simple LLM call
**You'll learn:** LLMChain, basic prompts, running chains

### 02 - Prompt Templates
**Concept:** Dynamic prompts with variables
**You'll learn:** PromptTemplate, variable substitution, reusable prompts

### 03 - Chains with Memory
**Concept:** Remember conversation history
**You'll learn:** ConversationBufferMemory, ConversationChain, context management

### 04 - Tools Integration
**Concept:** Give agents capabilities
**You'll learn:** Tool schemas, AgentExecutor, tool calling

### 05 - Sequential Chains
**Concept:** Multi-step workflows
**You'll learn:** SequentialChain, passing data between chains, complex workflows

### 06 - Router Chains
**Concept:** Conditional routing
**You'll learn:** RouterChain, LLMRouterChain, dynamic routing based on input

### 07 - Production Agent
**Concept:** Enterprise-grade agent
**You'll learn:** Error handling, logging, monitoring, best practices

---

## ğŸ§© Key Concepts

### What is a Chain?

A **chain** is a sequence of calls to LLMs or other utilities:

```python
# Simple chain
Prompt â†’ LLM â†’ Output

# Sequential chain
Prompt1 â†’ LLM1 â†’ Prompt2 â†’ LLM2 â†’ Output

# Tool chain
Prompt â†’ LLM â†’ Tool Call â†’ Tool Result â†’ LLM â†’ Output
```

### Why Use Chains?

**Without chains:**
```python
# Messy, hard to maintain
response1 = requests.post(...)
data = parse(response1)
response2 = requests.post(...format(data)...)
result = parse(response2)
```

**With chains:**
```python
# Clean, reusable
chain = PromptTemplate | LLM | OutputParser
result = chain.invoke({"input": "question"})
```

---

## ğŸ”‘ Core Components

### 1. LLMs (Language Models)

```python
from langchain_ollama import OllamaLLM

llm = OllamaLLM(
    model="qwen3:8b",
    temperature=0.7
)

response = llm.invoke("Hello!")
```

### 2. Prompts

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    template="Tell me about {topic}",
    input_variables=["topic"]
)

formatted = prompt.format(topic="AI")
# "Tell me about AI"
```

### 3. Chains

```python
from langchain.chains import LLMChain

chain = LLMChain(
    llm=llm,
    prompt=prompt
)

result = chain.run(topic="Python")
```

### 4. Memory

```python
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm,
    memory=memory
)

# First message
conversation.run("My name is John")
# "Nice to meet you, John!"

# Second message - remembers!
conversation.run("What's my name?")
# "Your name is John"
```

### 5. Tools

```python
from langchain.tools import Tool

def get_weather(city: str) -> str:
    return f"Weather in {city}: Sunny, 25Â°C"

weather_tool = Tool(
    name="get_weather",
    func=get_weather,
    description="Get weather for a city"
)
```

---

## ğŸ“ Learning Objectives

By the end of this section, you will:

1. âœ… Understand what chains are and when to use them
2. âœ… Build dynamic prompts with variables
3. âœ… Manage conversation memory
4. âœ… Integrate tools with agents
5. âœ… Create multi-step sequential workflows
6. âœ… Implement conditional routing
7. âœ… Build production-ready agents

---

## ğŸ”„ Progressive Complexity

```
01_basic_chain.py
   â†“ Add dynamic prompts
02_prompt_templates.py
   â†“ Add memory
03_chains_with_memory.py
   â†“ Add tools
04_tools_integration.py
   â†“ Add sequential steps
05_sequential_chains.py
   â†“ Add routing logic
06_router_chains.py
   â†“ Add production features
07_production_agent.py
```

---

## ğŸ› Common Issues & Solutions

### Issue 1: Import Errors

```bash
# Error: No module named 'langchain'
pip install langchain langchain-ollama

# Error: Cannot import OllamaLLM
pip install --upgrade langchain-ollama
```

### Issue 2: Ollama Connection

```python
# Test Ollama connection
import requests
response = requests.get("http://localhost:11434/api/tags")
print(response.status_code)  # Should be 200
```

### Issue 3: Chain Not Working

```python
# Enable verbose mode to see what's happening
chain = LLMChain(llm=llm, prompt=prompt, verbose=True)
```

---

## ğŸ“Š LangChain vs Others

| Feature | LangChain | LangGraph | CrewAI |
|---------|-----------|-----------|--------|
| Learning Curve | Easy âœ… | Moderate | Moderate |
| Best For | Simple chains | Complex workflows | Multi-agent |
| Setup Time | 5 min | 10 min | 15 min |
| Memory | Built-in âœ… | Manual | Built-in |
| Tools | Easy âœ… | Manual | Easy |
| Routing | Limited | Excellent | Good |

---

## ğŸ¯ When to Use LangChain

**Use LangChain when:**
- âœ… Building your first agent
- âœ… Simple conversational AI
- âœ… Quick prototypes
- âœ… Learning fundamentals
- âœ… Sequential workflows

**Don't use LangChain when:**
- âŒ Complex state management needed â†’ Use LangGraph
- âŒ Multi-agent systems â†’ Use CrewAI
- âŒ Need graph visualization â†’ Use LangGraph

---

## ğŸš€ Next Steps

After completing this section:

1. Move to **LangGraph** for complex workflows
2. Or jump to **CrewAI** for multi-agent systems
3. Or continue to **03-embeddings-rag** for knowledge retrieval

---

## ğŸ“š Resources

- [LangChain Docs](https://python.langchain.com/)
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [Ollama Integration](https://python.langchain.com/docs/integrations/llms/ollama)

---

**Ready to start?** Run `python 01_basic_chain.py` â†’
