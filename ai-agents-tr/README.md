**Not:** `ai-agents-tr` klasÃ¶rÃ¼, orijinal `ai-agents` klasÃ¶rÃ¼nÃ¼n TÃ¼rkÃ§e Ã§evirisidir. GeliÅŸtirme ve test sÃ¼reÃ§leri orijinal klasÃ¶rde tamamlandÄ±ÄŸÄ±nda, bu `-tr` klasÃ¶rÃ¼ birebir aynÄ± kod iÃ§eriÄŸiyle gÃ¼ncellenir; ancak tÃ¼m yorum satÄ±rlarÄ± ve README dosyalarÄ± TÃ¼rkÃ§e olarak sunulur.

# Yapay Zeka AjanlarÄ±: SÄ±fÄ±rdan Zirveye ğŸ¤–

> Sadece *nasÄ±l* kullanÄ±lacaÄŸÄ±nÄ± deÄŸil, *neden* frameworklere ihtiyacÄ±nÄ±z olduÄŸunu anlayarak Ã¼retim seviyesinde yapay zeka ajanlarÄ± oluÅŸturmayÄ± Ã¶ÄŸrenin.

[![Python](https://img.shields.io/badge/Python-3.11+-green.svg)](https://www.python.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLMs-blue.svg)](https://ollama.ai/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Agents-orange.svg)](https://github.com/langchain-ai/langgraph)

**OluÅŸturan:** [Beyhan MEYRALI](https://www.linkedin.com/in/beyhanmeyrali/)

> ğŸ”— **LinkedIn'de Ã–ne Ã‡Ä±kanlar:** [Duyurunun tamamÄ±nÄ± okuyun](https://lnkd.in/dDJE6VZH)

---

## ğŸ¯ Felsefe

**ChatGPT'ye bir mesaj gÃ¶nderdiÄŸinizde tam olarak ne olduÄŸunu biliyor musunuz?**

Ã‡oÄŸu eÄŸitim, karmaÅŸÄ±klÄ±ÄŸÄ± kÃ¼tÃ¼phanelerin arkasÄ±na gizler. "Sadece bu framework'Ã¼ iÃ§e aktarÄ±n ve Ã§alÄ±ÅŸtÄ±rÄ±n."

**Ben, Ã¶ÄŸrenmenin en iyi yolunun sÄ±fÄ±rdan, yerel olarak inÅŸa etmek ve deÄŸiÅŸkenlerin debugger'da nasÄ±l deÄŸiÅŸtiÄŸini izlemek olduÄŸuna inanÄ±yorum.**

### YZ Frameworklerini KÃ¶rÃ¼ne KullanmayÄ±n. Ã–nce *Neden* Ä°htiyacÄ±nÄ±z OlduÄŸunu Ã–ÄŸrenin. ğŸ› ï¸

Ä°ÅŸte bu yÃ¼zden bu aÃ§Ä±k kaynak serisini baÅŸlattÄ±m: **Yapay Zeka AjanlarÄ± - SÄ±fÄ±rdan Zirveye.**

Ã‡oÄŸu eÄŸitim doÄŸrudan karmaÅŸÄ±k frameworklere atlar ve sizi aslÄ±nda ne olduÄŸu konusunda kafanÄ±z karÄ±ÅŸÄ±k bÄ±rakÄ±r.

**Bu repo tam tersi bir yaklaÅŸÄ±mÄ± benimsiyor.**

---

## ğŸ—ºï¸ Yol HaritasÄ± - Ham Python'dan Ãœretime

Temelden inÅŸa ediyoruz:

1.  **Temel:** Ham HTTP Ã§aÄŸrÄ±larÄ± ve OOP Python sÄ±nÄ±flarÄ± âœ… *Åu an mevcut!*
2.  **Mekanik:** Manuel araÃ§ Ã§aÄŸÄ±rma ve Ã¶zyineleme (recursion) âœ… *Åu an mevcut!*
3.  **FarkÄ±ndalÄ±k:** Manuel durum yÃ¶netiminin *neden* karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ±nÄ± anlamak
4.  **Ã‡Ã¶zÃ¼m:** Frameworklerin TanÄ±tÄ±mÄ± (LangChain, LangGraph, CrewAI) âœ… *Åu an mevcut!*
5.  **Entegrasyon:** VektÃ¶r veritabanlarÄ± ile RAG Sistemleri ğŸš§ *YakÄ±nda*
6.  **HafÄ±za:** Letta (MemGPT) ile uzun sÃ¼reli baÄŸlam ğŸš§ *YakÄ±nda*
7.  **Ses:** Tam Sesli Asistan ğŸš§ *YakÄ±nda*

---

## ğŸ“ Bu Repoyu NasÄ±l KullanmalÄ±sÄ±nÄ±z

1.  Teori iÃ§in her klasÃ¶rdeki **README'yi okuyun**
2.  PratiÄŸi gÃ¶rmek iÃ§in **Kodu bir debugger ile Ã§alÄ±ÅŸtÄ±rÄ±n**
3.  **YorumlarÄ± Ä°nceleyin** - Her betikte kapsamlÄ± aÃ§Ä±klamalar var

Her ÅŸey yerel olarak **Ollama** ve **Qwen** ile Ã§alÄ±ÅŸÄ±r. **API anahtarÄ± gerekmez.**

---

## ğŸš€ Ne Ä°nÅŸa Edeceksiniz

Bu rehberin sonunda, ChatGPT'nin ses moduna benzer **tam iÅŸlevsel bir Sesli GPT** inÅŸa edeceksiniz, ÅŸunlarÄ± iÃ§erecek:
- ğŸ™ï¸ GerÃ§ek zamanlÄ± konuÅŸma tanÄ±ma (Whisper)
- ğŸ§  AkÄ±llÄ± konuÅŸma yÃ¶netimi (LangGraph)
- ğŸ’¾ Uzun sÃ¼reli hafÄ±za (Letta/MemGPT)
- ğŸ”§ AraÃ§ kullanÄ±mÄ± ve fonksiyon Ã§aÄŸÄ±rma
- ğŸ—£ï¸ DoÄŸal metin-konuÅŸma yanÄ±tlarÄ±
- ğŸ  **%100 makinenizde yerel olarak Ã§alÄ±ÅŸÄ±r**

---

## ğŸ“– Ã–ÄŸrenme Felsefesi

### Bu Rehber Neden FarklÄ±

1.  **Framework Kullanmadan Ã–nce SÄ±fÄ±rdan Ä°nÅŸa Et** - Sadece "nasÄ±l"Ä± deÄŸil, "neden"i anla
2.  **Ã–nce-Yerel** - Her ÅŸey Ollama (yerel LLM'ler) ve yerel Whisper Ã¼zerinde Ã§alÄ±ÅŸÄ±r
3.  **Debugger Dostu** - Bir debugger ile adÄ±m adÄ±m ilerlemek iÃ§in tasarlanmÄ±ÅŸ, yoÄŸun yorumlu kod
4.  **HTTP/REST Ã–rnekleri** - Her Ã¶rnek `curl` komutlarÄ± iÃ§erir, bÃ¶ylece HTTP katmanÄ±nÄ± anlarsÄ±nÄ±z
5.  **UygulamalÄ±** - Oyuncak Ã¶rnekler deÄŸil, gerÃ§ek uygulamalar inÅŸa edin
6.  **Kara Kutu Yok** - LLM'lerin, araÃ§larÄ±n, ajanlarÄ±n ve hafÄ±zanÄ±n arka planda nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlayÄ±n

### Ã–nemli Kavram: LLM'ler Durumsuzdur (Stateless)!

ğŸ”´ **Kritik AnlayÄ±ÅŸ**: LLM'ler veri SAKLAMAZ. Onlar hesap makineleri gibidir:
- Girdi â†’ Ä°ÅŸleme â†’ Ã‡Ä±ktÄ±
- Ã–nceki konuÅŸmalarÄ±n hafÄ±zasÄ± yoktur (konuÅŸma geÃ§miÅŸini gÃ¶ndermezseniz)
- Verileriniz hakkÄ±nda bilgisi yoktur (fine-tune etmezseniz veya RAG kullanmazsanÄ±z)
- Her API Ã§aÄŸrÄ±sÄ± baÄŸÄ±msÄ±zdÄ±r

Bu yÃ¼zden ÅŸunlara ihtiyacÄ±mÄ±z var:
- **BaÄŸlam yÃ¶netimi** - KonuÅŸma geÃ§miÅŸini gÃ¶nderme
- **RAG (EriÅŸim)** - VektÃ¶r veritabanlarÄ±ndan ilgili verileri getirme
- **HafÄ±za sistemleri** - Uzun sÃ¼reli baÄŸlamÄ± kalÄ±cÄ± hale getirme (Letta/MemGPT)
- **Fine-tuning** - Model aÄŸÄ±rlÄ±klarÄ±nÄ± gerÃ§ekten deÄŸiÅŸtirme (bkz. `../fine-tuning/`)

---

## ğŸ—‚ï¸ Kurs YapÄ±sÄ±

### ğŸ“š [00-llm-basics](./00-llm-basics) - Temeli Anlamak
**SÃ¼re:** 2-3 saat

**Ne Ã–ÄŸreneceksiniz:**
- LLM'ler aslÄ±nda nasÄ±l Ã§alÄ±ÅŸÄ±r (durumsuz hesaplama)
- LLM'ler neden hiÃ§bir ÅŸeyi "hatÄ±rlamaz"
- Ollama ile temel API Ã§aÄŸrÄ±larÄ±
- Daha iyi UX iÃ§in akÄ±ÅŸ (streaming) yanÄ±tlarÄ±
- HTTP anlayÄ±ÅŸÄ± iÃ§in basit curl Ã¶rnekleri
- Prompt teknikleri ve sistem promptlarÄ±

**Ana Fikir:** LLM'ler gÃ¼Ã§lÃ¼ Ã¶rÃ¼ntÃ¼ eÅŸleÅŸtiricilerdir, veritabanÄ± deÄŸildirler.

---

### ğŸ”§ [01-tool-calling](./01-tool-calling) - LLM'lere SÃ¼per GÃ¼Ã§ler Vermek
**SÃ¼re:** 3-4 saat

**Ne Ã–ÄŸreneceksiniz:**
- Fonksiyon/araÃ§ Ã§aÄŸÄ±rma temelleri
- LLM'ler araÃ§larÄ± ne zaman kullanacaÄŸÄ±na nasÄ±l karar verir
- **Ã–zyinelemeli (Recursive) araÃ§ Ã§aÄŸÄ±rma** (iÅŸin sÄ±rrÄ±!)
- GerÃ§ek dÃ¼nya Ã¶rnekleri: Hava durumu API'si, VeritabanÄ± sorgularÄ±
- Hata yÃ¶netimi ve yeniden deneme mantÄ±ÄŸÄ±
- Ã‡ok adÄ±mlÄ± araÃ§ orkestrasyonu

**Ana Ã–rnekler:**
- âœ… Temel hava durumu aracÄ± (tek Ã§aÄŸrÄ±)
- âœ… ERP/VeritabanÄ± entegrasyonu
- âœ… SÄ±rayla birden fazla aracÄ± Ã§aÄŸÄ±rabilen Ã¶zyinelemeli ajan
- âœ… Her uÃ§ nokta iÃ§in curl Ã¶rnekleri

**Ana Fikir:** AraÃ§lar, LLM'leri sohbet botlarÄ±ndan ajanlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

---

## ğŸ¤” Neden Frameworklere Ä°htiyacÄ±mÄ±z Var? (FarkÄ±ndalÄ±k)

**Bu en Ã¶nemli bÃ¶lÃ¼mdÃ¼r.** `01-tool-calling` iÃ§inde manuel araÃ§ Ã§aÄŸÄ±rmayÄ± inÅŸa ettikten sonra temelleri anlayacaksÄ±nÄ±z. Ancak iÅŸler karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ±nda ne olur?

### Sorun: Manuel Durum YÃ¶netimi HÄ±zla KarmaÅŸÄ±klaÅŸÄ±r

Diyelim ki manuel bir Ã¶zyinelemeli ajan inÅŸa ettiniz (Ã¶rneÄŸin `01-tool-calling/03_recursive_agent.py` gibi). Basit durumlar iÃ§in harika Ã§alÄ±ÅŸÄ±r:

```python
# Basit durum: Gayet iyi Ã§alÄ±ÅŸÄ±r!
KullanÄ±cÄ±: "Tokyo'da hava nasÄ±l?"
â†’ LLM get_weather("Tokyo") Ã§aÄŸÄ±rÄ±r
â†’ Sonucu dÃ¶ndÃ¼r
âœ… 2 adÄ±mda bitti
```

Peki ya bu gerÃ§ek dÃ¼nya senaryolarÄ±?

#### Senaryo 1: Dallanan MantÄ±kla Ã‡ok AdÄ±mlÄ± Ä°ÅŸlem
```python
KullanÄ±cÄ±: "En iyi 3 yapay zeka ÅŸirketini araÅŸtÄ±r, sonra her biri iÃ§in:
       1. Hisse senedi fiyatÄ±nÄ± al
       2. En son haberlerini analiz et
       3. OnlarÄ± karÅŸÄ±laÅŸtÄ±r ve birini Ã¶ner"

Manuel yaklaÅŸÄ±m sorunlarÄ±:
âŒ Hangi ÅŸirkette olduÄŸunuzu nasÄ±l takip edersiniz? (Durum yÃ¶netimi)
âŒ 2. adÄ±m bir ÅŸirket iÃ§in baÅŸarÄ±sÄ±z olursa ne olur? (Hata kurtarma)
âŒ AraÅŸtÄ±rmayÄ± nasÄ±l paralel hale getirirsiniz? (EÅŸzamanlÄ±lÄ±k)
âŒ YarÄ±da Ã§Ã¶kerse nasÄ±l devam edersiniz? (KalÄ±cÄ±lÄ±k)
âŒ Hangi adÄ±mÄ±n baÅŸarÄ±sÄ±z olduÄŸunu nasÄ±l ayÄ±klarsÄ±nÄ±z? (GÃ¶zlemlenebilirlik)
```

#### Senaryo 2: KoÅŸullu DÃ¶ngÃ¼ler
```python
KullanÄ±cÄ±: "Paris'te geceliÄŸi 100$'Ä±n altÄ±nda bir otel bulana kadar aramaya devam et"

Manuel yaklaÅŸÄ±m sorunlarÄ±:
âŒ VazgeÃ§meden Ã¶nce kaÃ§ iterasyon? (DÃ¶ngÃ¼ kontrolÃ¼)
âŒ Sonsuz dÃ¶ngÃ¼leri nasÄ±l Ã¶nlersiniz? (GÃ¼venlik)
âŒ Neleri denediÄŸinizi nasÄ±l takip edersiniz? (HafÄ±za)
âŒ Ya LLM halÃ¼sinasyon gÃ¶rÃ¼r ve aracÄ± hiÃ§ Ã§aÄŸÄ±rmazsa? (DoÄŸrulama)
```

#### Senaryo 3: Ä°nsan DÃ¶ngÃ¼de (Human-in-the-Loop)
```python
KullanÄ±cÄ±: "Bir e-posta taslaÄŸÄ± hazÄ±rla, incelememe izin ver, sonra gÃ¶nder"

Manuel yaklaÅŸÄ±m sorunlarÄ±:
âŒ YÃ¼rÃ¼tmeyi nasÄ±l duraklatÄ±p onay beklersiniz? (Kesmeler)
âŒ Tam olarak aynÄ± durumdan nasÄ±l devam edersiniz? (Kontrol noktasÄ± oluÅŸturma)
âŒ KullanÄ±cÄ± taslaÄŸÄ± deÄŸiÅŸtirmek isterse ne olur? (Durum gÃ¼ncellemeleri)
```

#### Senaryo 4: Ã‡oklu Ajan Ä°ÅŸbirliÄŸi
```python
KullanÄ±cÄ±: "Bir araÅŸtÄ±rmacÄ± veri bulsun, bir analist iÅŸlesin,
       ve bir yazar rapor oluÅŸtursun"

Manuel yaklaÅŸÄ±m sorunlarÄ±:
âŒ Ajanlar nasÄ±l iletiÅŸim kurar? (Mesaj iletimi)
âŒ Ajanlar arasÄ±nda nasÄ±l yÃ¶nlendirme yaparsÄ±nÄ±z? (Orkestrasyon)
âŒ AjanlarÄ±n farklÄ± araÃ§lara ihtiyacÄ± varsa ne olur? (BaÄŸlam izolasyonu)
âŒ 10 ajan Ã— 10 araÃ§ = 100 aracÄ± nasÄ±l yÃ¶netirsiniz? (BaÄŸlam ÅŸiÅŸmesi)
```

### Manuel Ã‡Ã¶zÃ¼m Bir Kabusa DÃ¶nÃ¼ÅŸÃ¼r

TÃ¼m bunlarÄ± manuel olarak halletmeye Ã§alÄ±ÅŸÄ±rsanÄ±z, kodunuz ÅŸuna dÃ¶nÃ¼ÅŸÃ¼r:

```python
# Sizin gÃ¼zel 50 satÄ±rlÄ±k Ã¶zyinelemeli ajanÄ±nÄ±z ÅŸuna dÃ¶nÃ¼ÅŸÃ¼r...
class ManuelKarmasikAjan:
    def __init__(self):
        self.state = {}  # Manuel durum takibi
        self.history = []  # Manuel geÃ§miÅŸ
        self.checkpoints = {}  # Manuel kalÄ±cÄ±lÄ±k
        self.retry_counts = {}  # Manuel hata yÃ¶netimi
        self.loop_guards = {}  # Manuel dÃ¶ngÃ¼ Ã¶nleme
        self.pending_approvals = {}  # Manuel insan-dÃ¶ngÃ¼de
        # ... 500 satÄ±r daha basmakalÄ±p kod ...
    
    def execute(self, query):
        # 1000 satÄ±rlÄ±k if/else makarna kodu
        # Bunu ayÄ±klarken iyi ÅŸanslar! ğŸ˜±
```

**AslÄ±nda bir framework'Ã¼ yeniden inÅŸa ediyorsunuz... ama kÃ¶tÃ¼ bir ÅŸekilde.**

### Sahneye Ã‡Ä±kar: Ajan Frameworkleri

Ä°ÅŸte **tam da bu yÃ¼zden** LangGraph ve CrewAI gibi frameworkler var. ÅunlarÄ± saÄŸlarlar:

| Sorun | Framework Ã‡Ã¶zÃ¼mÃ¼ |
|---------|-------------------|
| Durum yÃ¶netimi | Tip tanÄ±mlÄ± ÅŸemalarla yerleÅŸik durum grafikleri |
| Hata kurtarma | Otomatik yeniden denemeler ve yedek yollar |
| KalÄ±cÄ±lÄ±k | Ä°ÅŸ akÄ±ÅŸlarÄ±nÄ± sÃ¼rdÃ¼rmek iÃ§in kontrol noktalarÄ± (checkpointers) |
| DÃ¶ngÃ¼ler & Ã§evrimler | Maksimum iterasyonlu kontrollÃ¼ Ã§evrimler |
| Ä°nsan-dÃ¶ngÃ¼de | Kesme/devam etme mekanizmalarÄ± |
| Ã‡oklu ajan | SÃ¼pervizÃ¶r kalÄ±plarÄ± ve mesaj yÃ¶nlendirme |
| BaÄŸlam ÅŸiÅŸmesi | HiyerarÅŸik grafikler ve araÃ§ yÃ¶nlendirme |
| Hata ayÄ±klama | GÃ¶rsel grafik inceleme ve izleme |

### "Aha!" AnÄ±

Manuel durum yÃ¶netimiyle boÄŸuÅŸtuktan sonra ÅŸunlarÄ± takdir edeceksiniz:

```python
# LangGraph: AynÄ± karmaÅŸÄ±k iÅŸ akÄ±ÅŸÄ± 50 satÄ±rda
from langgraph.graph import StateGraph, END

graph = StateGraph(AgentState)
graph.add_node("researcher", research_node)
graph.add_node("analyst", analyst_node)
graph.add_node("writer", writer_node)
graph.add_conditional_edges("researcher", should_continue)
graph.add_edge("analyst", "writer")
graph.set_entry_point("researcher")

app = graph.compile(checkpointer=MemorySaver())  # â† KalÄ±cÄ±lÄ±k!
result = app.invoke(input, config={"thread_id": "123"})  # â† Devam ettirilebilir!
```

**Ä°ÅŸte frameworklerin gÃ¼cÃ¼ budur.** Sihir deÄŸilâ€”sadece yaygÄ±n kalÄ±plar iÃ§in iyi tasarlanmÄ±ÅŸ soyutlamalar.

---

### ğŸ•¸ï¸ [02-agent-frameworks](./02-agent-frameworks) - Profesyonel Ajan GeliÅŸtirme
**SÃ¼re:** 6-8 saat

**Ne Ã–ÄŸreneceksiniz:**
- **LangGraph** - KarmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± iÃ§in durum makineleri
- **CrewAI** - Ã‡oklu ajan iÅŸbirliÄŸi
- Ne zaman framework, ne zaman ham araÃ§ Ã§aÄŸÄ±rma kullanÄ±lmalÄ±
- Grafik tabanlÄ± ajan tasarÄ±m kalÄ±plarÄ±
- Ajan yÃ¼rÃ¼tme akÄ±ÅŸlarÄ±nÄ± ayÄ±klama

**Projeler:**
- ğŸ¯ MÃ¼ÅŸteri destek ajanÄ± (LangGraph)
- ğŸ¯ Ã‡oklu ajan araÅŸtÄ±rma ekibi (CrewAI)
- ğŸ¯ Ä°ÅŸ akÄ±ÅŸÄ± otomasyon ajanÄ±

**Ana Fikir:** Frameworkler, karmaÅŸÄ±k ajan davranÄ±ÅŸlarÄ± iÃ§in yapÄ± saÄŸlar.

---

### ğŸ“Š [03-rag-systems](./03-rag-systems) - LLM'lere Verilerinizi Ã–ÄŸretmek
**SÃ¼re:** 5-6 saat

**Ne Ã–ÄŸreneceksiniz:**
- VektÃ¶r veritabanlarÄ± (Qdrant, ChromaDB)
- Embeddingler ve anlamsal arama
- Belge iÅŸleme ve parÃ§alama stratejileri
- LangGraph entegrasyonu ile RAG
- Performans optimizasyonu

**RAG Neden Ã–nemli:**
- LLM'ler SÄ°ZÄ°N verilerinizi bilmez
- Fine-tuning pahalÄ± ve yavaÅŸtÄ±r
- RAG gerÃ§ek zamanlÄ±, gÃ¼ncellenebilir bilgi saÄŸlar
- Ã–zel/dinamik veriler iÃ§in uygun maliyetlidir

**Projeler:**
- ğŸ“š Belge Soru-Cevap sistemi
- ğŸ“š Kod arama asistanÄ±
- ğŸ“š Åirket bilgi tabanÄ±

**Ana Fikir:** RAG, LLM'leri sizin dÃ¼nyanÄ±za baÄŸlama yolunuzdur.

---

### ğŸ§  [04-memory-systems](./04-memory-systems) - Uzun SÃ¼reli BaÄŸlam
**SÃ¼re:** 4-5 saat

**Ne Ã–ÄŸreneceksiniz:**
- BaÄŸlam pencereleri neden yeterli deÄŸil
- **Letta (MemGPT)** mimarisi
- Uzun sÃ¼reli hafÄ±za kalÄ±plarÄ±
- BaÄŸlam Ã¶nceliklendirme stratejileri
- Letta + LangGraph entegrasyonu

**HafÄ±za Sorunu:**
```
HafÄ±za Olmadan:
KullanÄ±cÄ±: "AdÄ±m John"
YZ: "TanÄ±ÅŸtÄ±ÄŸÄ±mÄ±za memnun oldum, John"
[5 dakika sonra]
KullanÄ±cÄ±: "AdÄ±m ne?"
YZ: "Bilmiyorum, bana sÃ¶ylemedin"

Letta ile:
KullanÄ±cÄ±: "AdÄ±m John"
YZ: "TanÄ±ÅŸtÄ±ÄŸÄ±mÄ±za memnun oldum, John" [uzun sÃ¼reli hafÄ±zaya kaydeder]
[5 dakika sonra]
KullanÄ±cÄ±: "AdÄ±m ne?"
YZ: "AdÄ±n John!" [hafÄ±zadan getirir]
```

**Ana Fikir:** HafÄ±za sistemleri gerÃ§ekten kalÄ±cÄ± asistanlar saÄŸlar.

---

### ğŸ™ï¸ [05-voice-gpt](./05-voice-gpt) - Sesli AsistanÄ±nÄ±zÄ± Ä°nÅŸa Etmek
**SÃ¼re:** 8-10 saat

**Ne Ã–ÄŸreneceksiniz:**
- **Whisper** entegrasyonu (yerel konuÅŸmadan yazÄ±ya)
- Yerel modellerle metinden konuÅŸmaya (TTS)
- GerÃ§ek zamanlÄ± ses akÄ±ÅŸÄ±
- KonuÅŸmalar iÃ§in LangGraph durum yÃ¶netimi
- Her ÅŸeyi birleÅŸtirme: Whisper â†’ LangGraph â†’ Letta â†’ TTS

**Final Projesi: Sesli GPT**
```
Siz â†’ Whisper (STT) â†’ LangGraph (Ajan) â†’ Letta (HafÄ±za) â†’ TTS â†’ Siz
          â†“                    â†“                  â†“
      "Hava nasÄ±l?"       [AraÃ§larÄ± kullanÄ±r] [Ã–nceki konuÅŸmalarÄ±
                           [RAG'dan getirir]    hatÄ±rlar]
```

**Ana Ã–zellikler:**
- ğŸ¤ Eller serbest sesli etkileÅŸim
- ğŸ§  KonuÅŸma baÄŸlamÄ±nÄ± hatÄ±rlar
- ğŸ” Belgelerinizi arayabilir (RAG)
- ğŸ› ï¸ AraÃ§larÄ± Ã§aÄŸÄ±rabilir (hava durumu, takvim vb.)
- ğŸ  %100 yerel olarak Ã§alÄ±ÅŸÄ±r

**Ana Fikir:** Bu, Ã¶ÄŸrendiÄŸiniz her ÅŸeyin zirvesidir.

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Ã–n KoÅŸullar & Kurulum

#### AdÄ±m 1: Ollama Kurulumu

**Windows:**
```powershell
# https://ollama.ai/download/windows adresinden indirin
# Veya winget kullanÄ±n
winget install Ollama.Ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**macOS:**
```bash
brew install ollama
```

**Kurulumu DoÄŸrulayÄ±n:**
```bash
ollama --version
```

#### AdÄ±m 2: Gerekli Modelleri Ã‡ekin

Yerel ajanlar iÃ§in 2025'teki en iyi akÄ±l yÃ¼rÃ¼tme + araÃ§ Ã§aÄŸÄ±rma modeli olan **Qwen3:8b**'yi kullanÄ±yoruz:

```bash
# Ana LLM (Q4_K_M kuantizasyon - en iyi kalite/hÄ±z dengesi)
ollama pull qwen3:8b

# RAG iÃ§in embedding modeli (buna daha sonra ihtiyacÄ±nÄ±z olacak)
ollama pull nomic-embed-text

# Modellerin hazÄ±r olduÄŸunu doÄŸrulayÄ±n
ollama list
```

**Neden Qwen3:8b?**
- âœ… **MÃ¼kemmel araÃ§ Ã§aÄŸÄ±rma** - Yerel fonksiyon Ã§aÄŸÄ±rma desteÄŸi
- âœ… **GÃ¼Ã§lÃ¼ akÄ±l yÃ¼rÃ¼tme** - BirÃ§ok 13B modelden daha iyi performans gÃ¶sterir
- âœ… **Sorunsuz Ã§alÄ±ÅŸÄ±r** - ~5GB RAM, CPU'da hÄ±zlÄ±, GPU'da Ã§ok hÄ±zlÄ±
- âœ… **8B parametre** - Kalite vs kaynak kullanÄ±mÄ± iÃ§in tatlÄ± nokta
- âœ… **128K baÄŸlam penceresi** - BÃ¼yÃ¼k konuÅŸmalarÄ±/belgeleri yÃ¶netir
- âœ… **En yeni model** - 2024 sonlarÄ±nda yayÄ±nlandÄ±, son teknoloji mimari

#### AdÄ±m 3: Ollama Sunucusunu BaÅŸlatÄ±n

```bash
# Ollama kurulumdan sonra varsayÄ±lan olarak servis olarak Ã§alÄ±ÅŸÄ±r
# Ancak gerekirse manuel olarak baÅŸlatÄ±n:
ollama serve

# Sunucuyu test edin
curl http://localhost:11434/api/tags
```

#### AdÄ±m 4: Docker Kurulumu (Sadece Qdrant iÃ§in)

Docker'Ä± **SADECE** Qdrant (vektÃ¶r veritabanÄ±) iÃ§in kullanÄ±yoruz. DiÄŸer her ÅŸey yerel Ã§alÄ±ÅŸÄ±r.

**Windows/Mac:**
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) yÃ¼kleyin

**Linux:**
```bash
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER
# Grup deÄŸiÅŸikliklerinin etkili olmasÄ± iÃ§in Ã§Ä±kÄ±ÅŸ yapÄ±p tekrar girin
```

#### AdÄ±m 5: Qdrant'Ä± BaÅŸlatÄ±n (Tek Komut!)

```bash
cd ai-agents

# docker-compose kullanarak Qdrant'Ä± baÅŸlatÄ±n
docker compose up -d

# Qdrant'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulayÄ±n
curl http://localhost:6333/health

# Qdrant Web ArayÃ¼zÃ¼ne EriÅŸim
# TarayÄ±cÄ±yÄ± aÃ§Ä±n: http://localhost:6333/dashboard
```

**Docker'da ne Ã§alÄ±ÅŸÄ±r:**
- âœ… Qdrant (vektÃ¶r veritabanÄ±) - Ä°zolasyon ve kolay yÃ¶netim iÃ§in Docker

**Yerel olarak ne Ã§alÄ±ÅŸÄ±r (Docker'da DEÄÄ°L):**
- âœ… Ollama (daha iyi GPU eriÅŸimi, daha hÄ±zlÄ± Ã§Ä±karÄ±m)
- âœ… Python ajanlarÄ± (IDE'nizle daha kolay hata ayÄ±klama)
- âœ… SQLite (dosya tabanlÄ±, sunucu gerekmez)
- âœ… Whisper, TTS (daha iyi donanÄ±m eriÅŸimi)

#### AdÄ±m 6: Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin

```bash
# Sanal ortam oluÅŸturun (Ã¶nerilir)
python -m venv venv
source venv/bin/activate  # Windows'ta: venv\Scripts\activate

# TÃ¼m kurs iÃ§in tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt

# Veya gerektiÄŸinde bÃ¶lÃ¼m baÅŸÄ±na yÃ¼kleyin
cd 00-llm-basics
pip install -r requirements.txt
```

### Ä°lk Yapay Zeka AjanÄ±nÄ±z (30 saniye)

```bash
# curl ile test edin
curl -X POST http://localhost:11434/api/chat -d '{
  "model": "qwen3:8b",
  "messages": [{"role": "user", "content": "Merhaba! 2+2 kaÃ§tÄ±r?"}],
  "stream": false
}'

# Veya ilk Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±rÄ±n
cd 00-llm-basics
python 01_basic_chat.py
```

### Kurulumunuzu DoÄŸrulayÄ±n

Bu hÄ±zlÄ± saÄŸlÄ±k kontrolÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Ollama'yÄ± kontrol et
ollama list | grep qwen3:8b

# Qdrant'Ä± kontrol et (baÅŸlattÄ±ysanÄ±z)
curl http://localhost:6333/health

# Python ortamÄ±nÄ± kontrol et
python -c "import requests; print('âœ… Python kurulumu TAMAM')"
```

TÃ¼m kontroller geÃ§erse, baÅŸlamaya hazÄ±rsÄ±nÄ±z! ğŸ‰

---

## ğŸ’¡ Temel Kavramlar AÃ§Ä±klamasÄ±

### 0. Her YazÄ±lÄ±m Yapay Zeka Kullanabilir (Sadece REST API!)

**ğŸ”‘ Kritik AnlayÄ±ÅŸ:** LLM'leri kullanmak iÃ§in Python'a, frameworklere veya Ã¶zel kÃ¼tÃ¼phanelere ihtiyacÄ±nÄ±z yok!

LLM'lere **basit HTTP REST API Ã§aÄŸrÄ±larÄ±** ile eriÅŸilir. Bu ÅŸu anlama gelir:

```javascript
// JavaScript/Node.js
fetch('http://localhost:11434/api/chat', {
  method: 'POST',
  body: JSON.stringify({
    model: 'qwen3:8b',
    messages: [{role: 'user', content: 'Merhaba!'}]
  })
})

// Hatta curl!
curl -X POST http://localhost:11434/api/chat -d '{...}'
```

**Bunun AnlamÄ±:**
- âœ… **Mevcut web uygulamanÄ±za** YZ ekleyin (PHP, Ruby, Java, .NET vb.)
- âœ… REST Ã§aÄŸrÄ±larÄ± ile **eski sistemlerle** entegre edin
- âœ… Herhangi bir dilde **herhangi bir HTTP istemci kÃ¼tÃ¼phanesini** kullanÄ±n
- âœ… Python'da yeniden yazmaya gerek yok!
- âœ… **Mobil uygulamalarla** Ã§alÄ±ÅŸÄ±r (iOS, Android)
- âœ… **Excel VBA** bile HTTP Ã¼zerinden LLM'leri Ã§aÄŸÄ±rabilir!

**Bu kursta Python kullanÄ±yoruz Ã§Ã¼nkÃ¼:**
- Ã–ÄŸrenmesi ve okumasÄ± kolay
- Harika hata ayÄ±klama araÃ§larÄ±
- Zengin ekosistem (LangGraph, CrewAI vb.)

**Ama unutmayÄ±n:** REST API her yerden Ã§alÄ±ÅŸÄ±r!

---

### 1. BaÄŸlam ÅiÅŸmesi Sorunu (Neden HafÄ±za YÃ¶netimine Ä°htiyacÄ±nÄ±z Var)

**ğŸ”´ Kritik Sorun:** Her araÃ§ Ã§aÄŸrÄ±sÄ± baÄŸlam pencerenizi PATLATIR!

**Ã–rnek - Basit Bir Hava Durumu Sorgusu:**
```
Tur 1:
KullanÄ±cÄ±: "Tokyo'da hava nasÄ±l?"
â†’ BaÄŸlam: ~20 token

LLM YanÄ±tÄ±: [tool_call: get_weather(city="Tokyo")]
â†’ BaÄŸlam: ~50 token

AraÃ§ Sonucu: {"temp": 25, "condition": "sunny", "humidity": 60, ...}
â†’ BaÄŸlam: ~100 token

LLM Final CevabÄ±: "Tokyo'da hava 25Â°C ve gÃ¼neÅŸli"
â†’ BaÄŸlam: ~120 token

TOPLAM: TEK bir soru iÃ§in 120 token
```

**Åimdi bir konuÅŸmada 10 araÃ§ Ã§aÄŸrÄ±sÄ± ile:**
```
KullanÄ±cÄ± 10 soru sorar â†’ 10 araÃ§ Ã§aÄŸrÄ±sÄ± â†’ 10 sonuÃ§

BaÄŸlam boyutu: ~1,200 token (sadece araÃ§lar iÃ§in!)
ArtÄ± konuÅŸma geÃ§miÅŸi: ~2,000 token
TOPLAM: 3,200 token

Sorun: BaÄŸlam pencerenizi HIZLA tÃ¼ketiyorsunuz!
```

#### Bu Neden Ã–nemli

**BaÄŸlam Penceresi SÄ±nÄ±rlarÄ±:**
| Model | BaÄŸlam SÄ±nÄ±rÄ± | ÅiÅŸmeden Sonra Maliyet |
|-------|---------------|---------------------|
| Qwen3:8b | 128K token | Ãœcretsiz (yerel) ama daha yavaÅŸ |
| GPT-4 | 128K token | 1 milyon token baÅŸÄ±na 10$+ |
| Claude | 200K token | 1 milyon token baÅŸÄ±na 15$+ |

**ÅiÅŸme Kademesi:**
```
5 araÃ§ kullanan turlu konuÅŸma:

Tur 1:  120 token
Tur 2:  120 + 120 = 240 token
Tur 3:  240 + 120 = 360 token
Tur 4:  360 + 120 = 480 token
Tur 5:  480 + 120 = 600 token

10 turdan sonra: 1,200 token
50 turdan sonra: 6,000 token
100 turdan sonra: 12,000 token

HER SEFERÄ°NDE tÃ¼m Ã¶nceki araÃ§ Ã§aÄŸrÄ±larÄ±nÄ± + sonuÃ§larÄ±nÄ± gÃ¶nderiyorsunuz!
```

#### KÄ±sa SÃ¼reli vs Uzun SÃ¼reli HafÄ±za (Ã‡Ã¶zÃ¼m)

**KÄ±sa SÃ¼reli HafÄ±za (Ã‡alÄ±ÅŸma HafÄ±zasÄ±):**
```python
# LLM'in ÅŸu anda gÃ¶rdÃ¼ÄŸÃ¼
messages = [
    {"role": "system", "content": "Sen yardÄ±mcÄ± bir asistansÄ±n"},
    {"role": "user", "content": "Hava nasÄ±l?"},
    {"role": "assistant", "tool_calls": [...]},  # â† ÅiÅŸme!
    {"role": "tool", "content": "{...}"},        # â† ÅiÅŸme!
    {"role": "assistant", "content": "GÃ¼neÅŸli"}
]

Sorun: Bunu yÃ¶netmezseniz bu liste SONSUZA KADAR bÃ¼yÃ¼r!
```

**Uzun SÃ¼reli HafÄ±za (KalÄ±cÄ± Depolama):**
```python
# Letta/MemGPT yaklaÅŸÄ±mÄ±
core_memory = {
    "user_preferences": "Celsius sever, nemden nefret eder",
    "conversation_style": "KÄ±sa cevaplarÄ± tercih eder",
    "important_facts": "Tokyo'da yaÅŸÄ±yor, uzaktan Ã§alÄ±ÅŸÄ±yor"
}

# Sadece mevcut soru iÃ§in gerekeni getir
# ÅiÅŸmiÅŸ araÃ§ Ã§aÄŸrÄ± geÃ§miÅŸi yok!
```

#### Frameworkler BaÄŸlam ÅiÅŸmesini NasÄ±l Ã‡Ã¶zer

**âŒ Saf YaklaÅŸÄ±m (Frameworkler Olmadan YapacaÄŸÄ±nÄ±z):**
```python
# Her turda HER ÅEYÄ° gÃ¶nder
messages = [...]  # Tarihin tÃ¼m 10,000 tokenÄ±
response = llm.chat(messages)  # YavaÅŸ! PahalÄ±!
```

**âœ… LangGraph Ã‡Ã¶zÃ¼mÃ¼:**
```python
# Kontrol NoktasÄ± OluÅŸturma - Durumu kaydet, baÄŸlamÄ± kÄ±rp
from langgraph.checkpoint import MemorySaver

checkpointer = MemorySaver()

# Aktif baÄŸlamda sadece son N turu tut
# Eski turlar kontrol noktasÄ± deposuna kaydedilir
graph = StateGraph(state_schema)
graph.add_node("agent", agent_node)
graph.compile(checkpointer=checkpointer)

# BaÄŸlam kÃ¼Ã§Ã¼k kalÄ±r, geÃ§miÅŸ geri getirilebilir!
```

**âœ… CrewAI Ã‡Ã¶zÃ¼mÃ¼:**
```python
# Her ajanÄ±n sÄ±nÄ±rlÄ± baÄŸlamÄ± vardÄ±r
# YÃ¶netici ajanlar arasÄ±nda orkestrasyon yapar, Ã¶zetler
class ResearchCrew:
    def __init__(self):
        # AraÅŸtÄ±rmacÄ± sadece araÅŸtÄ±rma baÄŸlamÄ±nÄ± gÃ¶rÃ¼r
        self.researcher = Agent(
            role="Researcher",
            memory=ShortTermMemory(max_tokens=2000)
        )
        # Yazar sadece son Ã¶zeti gÃ¶rÃ¼r
        self.writer = Agent(
            role="Writer",
            memory=ShortTermMemory(max_tokens=2000)
        )
```

**âœ… Letta (MemGPT) Ã‡Ã¶zÃ¼mÃ¼:**
```python
# Ã‡ekirdek hafÄ±za (her zaman yÃ¼klÃ¼) + ArÅŸiv hafÄ±zasÄ± (gerektiÄŸinde getirilir)
agent = Agent(
    core_memory={
        "persona": "...",      # ~200 token (her zaman baÄŸlamda)
        "human": "..."         # ~200 token (her zaman baÄŸlamda)
    },
    archival_memory=QdrantMemory(  # SÄ±nÄ±rsÄ±z! RAG ile getirilir
        collection_name="user_123_memories"
    )
)

# Sadece ilgili hafÄ±zalar baÄŸlama Ã§ekilir
# KonuÅŸma geÃ§miÅŸinin %99'u Qdrant'ta kalÄ±r!
```

---

### 2. LLM'ler VeritabanÄ± DEÄÄ°LDÄ°R

```python
# âŒ YANLIÅ ZÄ°HÄ°NSEL MODEL
llm.remember("En sevdiÄŸim renk mavi")
print(llm.recall("En sevdiÄŸim renk ne?"))  # Bu mevcut deÄŸil!

# âœ… DOÄRU ZÄ°HÄ°NSEL MODEL
messages = [
    {"role": "user", "content": "En sevdiÄŸim renk mavi"},
    {"role": "assistant", "content": "AnlaÅŸÄ±ldÄ±!"},
    {"role": "user", "content": "En sevdiÄŸim renk ne?"}
]
# LLM her seferinde TÃœM mesajlarÄ± gÃ¶rÃ¼r ve yanÄ±t Ã¼retir
response = llm.chat(messages)
```

### 3. AraÃ§ Ã‡aÄŸÄ±rma Sadece YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã‡Ä±ktÄ±dÄ±r

```python
# LLM araÃ§larÄ± "Ã§alÄ±ÅŸtÄ±rmaz"
# "LÃ¼tfen bu fonksiyonu Ã§alÄ±ÅŸtÄ±r" diyen JSON Ã§Ä±ktÄ±sÄ± verir
{
  "function": "get_weather",
  "arguments": {"city": "Tokyo"}
}

# Fonksiyonu SÄ°Z Ã§alÄ±ÅŸtÄ±rÄ±rsÄ±nÄ±z
weather = get_weather("Tokyo")

# Sonra sonucu LLM'e SÄ°Z geri gÃ¶nderirsiniz
messages.append({"role": "tool", "content": weather})
response = llm.chat(messages)
```

---

## ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±

### Tam Yerel YÄ±ÄŸÄ±n (2025 Ãœretime HazÄ±r)

| BileÅŸen | Teknoloji | Neden Bu SeÃ§im |
|-----------|-----------|-----------------|
| **LLM** | Qwen3:8b (Q4_K_M) | En iyi araÃ§ Ã§aÄŸÄ±rma modeli, 128K baÄŸlam, gÃ¼Ã§lÃ¼ akÄ±l yÃ¼rÃ¼tme |
| **Embeddingler** | nomic-embed-text | #1 yerel embedding modeli, Qdrant-optimize |
| **VektÃ¶r VT** | Qdrant (Docker) | Ã‡ok hÄ±zlÄ±, HNSW, payload filtreleme, binary kuantizasyon |
| **Ä°liÅŸkisel VT** | SQLite | SÄ±fÄ±r yapÄ±landÄ±rma, dosya tabanlÄ±, konuÅŸma geÃ§miÅŸi iÃ§in mÃ¼kemmel |
| **Ajan Framework** | LangGraph | Ãœretim sÄ±nÄ±fÄ± durum makineleri, en iyi hata ayÄ±klama |
| **Ã‡oklu Ajan** | CrewAI | Ä°ÅŸbirlikÃ§i ajan ekipleri, rol tabanlÄ± iÅŸ akÄ±ÅŸlarÄ± |
| **HafÄ±za** | Letta (MemGPT) | Uzun sÃ¼reli hafÄ±za, kiÅŸilik evrimi |
| **GÃ¶zlemlenebilirlik** | LangFuse (yerel) | AÃ§Ä±k kaynak LLM izleme, Docker olmadan Ã§alÄ±ÅŸÄ±r |
| **KonuÅŸmadan YazÄ±ya** | Whisper (yerel) | OpenAI'nin modeli, yerel Ã§alÄ±ÅŸÄ±r |
| **Metinden KonuÅŸmaya** | Coqui TTS | Yerel, yÃ¼ksek kaliteli ses sentezi |
| **Web Otomasyonu** | Playwright | Ajanlar iÃ§in tarayÄ±cÄ± kontrolÃ¼ |
| **API Framework** | FastAPI | Modern Python web framework'Ã¼ |
| **ArayÃ¼z** | Streamlit/Gradio | HÄ±zlÄ± prototipleme, gÃ¼zel arayÃ¼zler |

### Neden Bu YÄ±ÄŸÄ±n KazanÄ±r

**Cloud LLM'lere KarÅŸÄ±:**

| Cloud LLM'ler | Yerel (Ollama + Qwen3:8b) |
|------------|---------------------------|
| ğŸ’° Token baÅŸÄ±na Ã¶deme (1M token iÃ§in 0.50$-2$) | âœ… **Sonsuza kadar Ã¼cretsiz** |
| ğŸ”“ Veri 3. tarafa gÃ¶nderilir | âœ… **%100 Ã¶zel** |
| ğŸŒ Ä°nternet gerektirir | âœ… **Ã‡evrimdÄ±ÅŸÄ± Ã§alÄ±ÅŸÄ±r** |
| âš¡ Ã‡ok hÄ±zlÄ± (bÃ¼yÃ¼k veri merkezleri) | âš¡ **Yeterince hÄ±zlÄ±** (5-10 tok/sn CPU, 80-120 GPU) |
| ğŸ¯ En iyi kalite (GPT-4) | ğŸ¯ **MÃ¼kemmel kalite** (akÄ±l yÃ¼rÃ¼tmede GPT-3.5'i yener) |
| ğŸ”§ API hÄ±z sÄ±nÄ±rlarÄ± | âœ… **SÄ±nÄ±r yok** |
| ğŸ“Š SÄ±nÄ±rlÄ± baÄŸlam (8-32K) | âœ… **128K baÄŸlam penceresi** |

**En Ä°yi Uygulama:** Bu yÄ±ÄŸÄ±nla yerel olarak prototipleyin, kritik parÃ§alarÄ± gerekirse buluta daÄŸÄ±tÄ±n.

### DonanÄ±m Gereksinimleri

**Minimum (Sadece CPU):**
- 16GB RAM (Model iÃ§in 12GB + sistem iÃ§in 4GB)
- 4-Ã§ekirdekli CPU
- 15GB disk alanÄ±

**Ã–nerilen (GPU):**
- 16GB RAM
- 8-Ã§ekirdekli CPU
- **6GB+ VRAM'li NVIDIA GPU** (RTX 3060, 4060 Ti vb.)
- 50GB disk alanÄ± (modeller + vektÃ¶r indeksleri iÃ§in)

---

## ğŸ“š Ã–ÄŸrenme Yolu Ã–nerileri

### Yol 1: Tam BaÅŸlangÄ±Ã§ (30-40 saat)
```
00-llm-basics â†’ 01-tool-calling â†’ 02-agent-frameworks â†’ 05-voice-gpt
```
*BaÅŸlangÄ±Ã§ta RAG ve Letta'yÄ± atlayÄ±n, temel ajan kavramlarÄ±na odaklanÄ±n*

### Yol 2: Ãœretime HÄ±zlÄ± GeÃ§iÅŸ (15-20 saat)
```
01-tool-calling â†’ 02-agent-frameworks (Sadece LangGraph) â†’ 03-rag-systems
```
*LLM temellerini bildiÄŸinizi varsayar, CrewAI ve Sesi atlar*

---

## ğŸ¤ KatkÄ±da Bulunma

Bu repo, topluluk iÃ§in bir Ã¶ÄŸrenme kaynaÄŸÄ±dÄ±r. ÅunlarÄ± bulursanÄ±z PR aÃ§maktan Ã§ekinmeyin:
- Hatalar
- Daha iyi aÃ§Ä±klamalar
- Yeni ajan Ã¶rnekleri
- Performans iyileÅŸtirmeleri

---

## ğŸ“„ Lisans

MIT LisansÄ± - Ä°stediÄŸiniz gibi kullanÄ±n, Ã¶ÄŸrenin ve inÅŸa edin!
